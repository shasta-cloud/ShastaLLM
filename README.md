# Shasta LLM Helper

Shasta LLM Helper is a tool designed to interact with users, monitor system health and anomalies, perform actions, and more. It is currently a backup for an LLM-based helper for the Shasta UI.

## Features

- Interact with users
- Obtain data about setups
- Monitor health and anomalies
- Perform actions

## Research and Suitability

This repository contains four attempts made for research and suitability. Each attempt explores different approaches and technologies to achieve the project's goals.

### 1. Assistant - app.py -  [Shasta helper based on phidata + tools + pandasai](https://github.com/shasta-cloud/ShastaLLM/tree/main/Assistant/README.md)
It contains PostgreSQL db + PgVector for LLM state and files.
A streamlit based Assistant which includes sevral function calling for tools.

### 2. ShastaLLM.py - [Shasta helper based on Langchain]()

### 3. ShastaChat.py

### 4. [RAG Shasta helper based on Langchain]()

### 4. olama_test.py - Simple ollama interacting

## Installation

This is the basic instructions for all attempts, refer to the links above for further info. 

## Usage


### 1. [Install](https://github.com/ollama/ollama?tab=readme-ov-file#macos) ollama and pull models

Pull the LLM you'd like to use:

```shell

ollama pull llama3
```
### 2. Install libraries

### 3. Run <file.py>


## License

License TBD...